# Context Normalization Pipeline

An end-to-end NLP pipeline for cleaning English text, translating it to Hindi using the Bhashini API, extracting key linguistic features, and simplifying Hindi text using AWS Bedrock LLMs.

This project is designed for real-world datasets (e.g., grievance text, free-form sentences) and includes progress tracking, fault tolerance, and clean modular design.

---

## ğŸš€ Features

- CSV-based input processing
- Robust text cleaning & normalization
- English â†’ Hindi translation via **Bhashini**
- Keyword extraction using **spaCy**
- Hindi simplification using **AWS Bedrock (Claude)**
- Automatic text column detection
- Progress bar with ETA (`tqdm`)
- Per-row error handling
- Clean, modular architecture

---

## ğŸ“ Project Structure

Context Normalization/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ input.csv # Input CSV file
â”‚ â”œâ”€â”€ output.csv # Generated output
â”‚
â”œâ”€â”€ config/
â”‚ â””â”€â”€ settings.py # Environment variable loader
â”‚
â”œâ”€â”€ services/
â”‚ â”œâ”€â”€ cleaner.py
â”‚ â”œâ”€â”€ bhashini_translate.py
â”‚ â”œâ”€â”€ pos_extractor.py
â”‚ â”œâ”€â”€ bedrock_llm.py
â”‚
â”œâ”€â”€ pipeline.py # Main pipeline script
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .env # NOT committed (gitignored)
â””â”€â”€ .gitignore


---

## ğŸ§  How the Pipeline Works

1. Reads text from a CSV file
2. Cleans and normalizes English sentences
3. Translates text from English to Hindi using Bhashini
4. Extracts linguistic keywords (nouns, verbs, adjectives, pronouns)
5. Identifies and replaces complex Hindi words using AWS Bedrock
6. Writes results to a CSV file

---

## ğŸ”§ Setup Instructions

### 1ï¸âƒ£ Clone Repository
```bash
git clone <your-repo-url>
cd Context-Normalization
2ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate
3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
python -m spacy download en_core_web_sm
4ï¸âƒ£ Configure Environment Variables
Create a .env file in the project root:

BHASHINI_API_KEY=your_bhashini_api_key
BHASHINI_USER_ID=your_bhashini_user_id
BHASHINI_API_URL=https://dhruva-api.bhashini.gov.in/services/inference/pipeline

AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_REGION=ap-south-1
BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0
âš ï¸ Never commit .env to GitHub

â–¶ï¸ Running the Pipeline
python pipeline.py
Output will be saved to:

data/output.csv
ğŸ§ª Input Format
The input CSV must contain one text column, such as:

sentence
This is a sample sentence
or

grievance_text
Non receipt of pension since last year
The pipeline auto-detects the correct column.

ğŸ“Œ Notes
Python version: 3.11 (recommended)

spaCy is not compatible with Python 3.14+

AWS Bedrock permissions must allow bedrock:InvokeModel

ğŸ“œ License
MIT License


---

# ğŸš« `.gitignore` (IMPORTANT)

Create **`.gitignore`** in root:

```gitignore
# Virtual environment
venv/

# Environment variables
.env
.env.*

# Python cache
__pycache__/
*.pyc

# Data outputs
data/output.csv

# OS files
.DS_Store
